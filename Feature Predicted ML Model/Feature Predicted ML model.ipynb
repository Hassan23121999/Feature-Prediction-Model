{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class PointCloudDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.points = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        class_to_idx = {self.classes[i]: i for i in range(len(self.classes))}\n",
    "\n",
    "        for idx, class_name in enumerate(self.classes):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for file_name in os.listdir(class_dir):\n",
    "                if file_name.lower().endswith('.txt'):\n",
    "                    file_path = os.path.join(class_dir, file_name)\n",
    "                    point_cloud = np.loadtxt(file_path)\n",
    "                    self.points.append(point_cloud)\n",
    "                    self.labels.append(class_to_idx[class_name])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.points)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.points[idx]), self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(PointNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.fc1 = nn.Linear(128, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, num_classes)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.adaptive_max_pool1d(x, 1).squeeze(-1)\n",
    "        x = F.relu(self.bn3(self.fc1(x)))\n",
    "        x = F.relu(self.bn4(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Step [10/100], Loss: 1.2002\n",
      "Epoch [1/30], Step [20/100], Loss: 1.0452\n",
      "Epoch [1/30], Step [30/100], Loss: 0.9865\n",
      "Epoch [1/30], Step [40/100], Loss: 0.7612\n",
      "Epoch [1/30], Step [50/100], Loss: 0.7346\n",
      "Epoch [1/30], Step [60/100], Loss: 0.7286\n",
      "Epoch [1/30], Step [70/100], Loss: 0.5647\n",
      "Epoch [1/30], Step [80/100], Loss: 0.6495\n",
      "Epoch [1/30], Step [90/100], Loss: 0.6282\n",
      "Epoch [1/30], Step [100/100], Loss: 0.5261\n",
      "Validation Accuracy: 53.62%\n",
      "Epoch [2/30], Step [10/100], Loss: 0.4165\n",
      "Epoch [2/30], Step [20/100], Loss: 0.5876\n",
      "Epoch [2/30], Step [30/100], Loss: 0.3909\n",
      "Epoch [2/30], Step [40/100], Loss: 0.3844\n",
      "Epoch [2/30], Step [50/100], Loss: 0.5096\n",
      "Epoch [2/30], Step [60/100], Loss: 0.4047\n",
      "Epoch [2/30], Step [70/100], Loss: 0.4277\n",
      "Epoch [2/30], Step [80/100], Loss: 0.6509\n",
      "Epoch [2/30], Step [90/100], Loss: 0.4104\n",
      "Epoch [2/30], Step [100/100], Loss: 0.3401\n",
      "Validation Accuracy: 74.62%\n",
      "Epoch [3/30], Step [10/100], Loss: 0.4870\n",
      "Epoch [3/30], Step [20/100], Loss: 0.4377\n",
      "Epoch [3/30], Step [30/100], Loss: 0.4881\n",
      "Epoch [3/30], Step [40/100], Loss: 0.4580\n",
      "Epoch [3/30], Step [50/100], Loss: 0.2887\n",
      "Epoch [3/30], Step [60/100], Loss: 0.3797\n",
      "Epoch [3/30], Step [70/100], Loss: 0.4643\n",
      "Epoch [3/30], Step [80/100], Loss: 0.3512\n",
      "Epoch [3/30], Step [90/100], Loss: 0.2684\n",
      "Epoch [3/30], Step [100/100], Loss: 0.3549\n",
      "Validation Accuracy: 74.00%\n",
      "Epoch [4/30], Step [10/100], Loss: 0.3309\n",
      "Epoch [4/30], Step [20/100], Loss: 0.5431\n",
      "Epoch [4/30], Step [30/100], Loss: 0.3887\n",
      "Epoch [4/30], Step [40/100], Loss: 0.3315\n",
      "Epoch [4/30], Step [50/100], Loss: 0.5464\n",
      "Epoch [4/30], Step [60/100], Loss: 0.3371\n",
      "Epoch [4/30], Step [70/100], Loss: 0.3552\n",
      "Epoch [4/30], Step [80/100], Loss: 0.5035\n",
      "Epoch [4/30], Step [90/100], Loss: 0.3314\n",
      "Epoch [4/30], Step [100/100], Loss: 0.3705\n",
      "Validation Accuracy: 57.00%\n",
      "Epoch [5/30], Step [10/100], Loss: 0.5095\n",
      "Epoch [5/30], Step [20/100], Loss: 0.3434\n",
      "Epoch [5/30], Step [30/100], Loss: 0.7521\n",
      "Epoch [5/30], Step [40/100], Loss: 0.3609\n",
      "Epoch [5/30], Step [50/100], Loss: 0.3595\n",
      "Epoch [5/30], Step [60/100], Loss: 0.5463\n",
      "Epoch [5/30], Step [70/100], Loss: 0.3809\n",
      "Epoch [5/30], Step [80/100], Loss: 0.3192\n",
      "Epoch [5/30], Step [90/100], Loss: 0.4265\n",
      "Epoch [5/30], Step [100/100], Loss: 0.3481\n",
      "Validation Accuracy: 74.00%\n",
      "Epoch [6/30], Step [10/100], Loss: 0.4355\n",
      "Epoch [6/30], Step [20/100], Loss: 0.3582\n",
      "Epoch [6/30], Step [30/100], Loss: 0.2509\n",
      "Epoch [6/30], Step [40/100], Loss: 0.6670\n",
      "Epoch [6/30], Step [50/100], Loss: 0.4385\n",
      "Epoch [6/30], Step [60/100], Loss: 0.3393\n",
      "Epoch [6/30], Step [70/100], Loss: 0.4751\n",
      "Epoch [6/30], Step [80/100], Loss: 0.3022\n",
      "Epoch [6/30], Step [90/100], Loss: 0.3528\n",
      "Epoch [6/30], Step [100/100], Loss: 0.3470\n",
      "Validation Accuracy: 73.12%\n",
      "Epoch [7/30], Step [10/100], Loss: 0.3324\n",
      "Epoch [7/30], Step [20/100], Loss: 0.2662\n",
      "Epoch [7/30], Step [30/100], Loss: 0.3822\n",
      "Epoch [7/30], Step [40/100], Loss: 0.3174\n",
      "Epoch [7/30], Step [50/100], Loss: 0.4147\n",
      "Epoch [7/30], Step [60/100], Loss: 0.2900\n",
      "Epoch [7/30], Step [70/100], Loss: 0.5609\n",
      "Epoch [7/30], Step [80/100], Loss: 0.3039\n",
      "Epoch [7/30], Step [90/100], Loss: 0.4186\n",
      "Epoch [7/30], Step [100/100], Loss: 0.4867\n",
      "Validation Accuracy: 70.62%\n",
      "Epoch [8/30], Step [10/100], Loss: 0.3694\n",
      "Epoch [8/30], Step [20/100], Loss: 0.4412\n",
      "Epoch [8/30], Step [30/100], Loss: 0.2725\n",
      "Epoch [8/30], Step [40/100], Loss: 0.3893\n",
      "Epoch [8/30], Step [50/100], Loss: 0.3242\n",
      "Epoch [8/30], Step [60/100], Loss: 0.2952\n",
      "Epoch [8/30], Step [70/100], Loss: 0.4478\n",
      "Epoch [8/30], Step [80/100], Loss: 0.3860\n",
      "Epoch [8/30], Step [90/100], Loss: 0.3241\n",
      "Epoch [8/30], Step [100/100], Loss: 0.3208\n",
      "Validation Accuracy: 75.25%\n",
      "Epoch [9/30], Step [10/100], Loss: 0.3539\n",
      "Epoch [9/30], Step [20/100], Loss: 0.3561\n",
      "Epoch [9/30], Step [30/100], Loss: 0.2543\n",
      "Epoch [9/30], Step [40/100], Loss: 0.3597\n",
      "Epoch [9/30], Step [50/100], Loss: 0.3193\n",
      "Epoch [9/30], Step [60/100], Loss: 0.3261\n",
      "Epoch [9/30], Step [70/100], Loss: 0.5211\n",
      "Epoch [9/30], Step [80/100], Loss: 0.3872\n",
      "Epoch [9/30], Step [90/100], Loss: 0.3137\n",
      "Epoch [9/30], Step [100/100], Loss: 0.3165\n",
      "Validation Accuracy: 73.75%\n",
      "Epoch [10/30], Step [10/100], Loss: 0.2756\n",
      "Epoch [10/30], Step [20/100], Loss: 0.3336\n",
      "Epoch [10/30], Step [30/100], Loss: 0.3862\n",
      "Epoch [10/30], Step [40/100], Loss: 0.3040\n",
      "Epoch [10/30], Step [50/100], Loss: 0.3822\n",
      "Epoch [10/30], Step [60/100], Loss: 0.3205\n",
      "Epoch [10/30], Step [70/100], Loss: 0.3229\n",
      "Epoch [10/30], Step [80/100], Loss: 0.5324\n",
      "Epoch [10/30], Step [90/100], Loss: 0.5331\n",
      "Epoch [10/30], Step [100/100], Loss: 0.3419\n",
      "Validation Accuracy: 72.25%\n",
      "Epoch [11/30], Step [10/100], Loss: 0.2921\n",
      "Epoch [11/30], Step [20/100], Loss: 0.3273\n",
      "Epoch [11/30], Step [30/100], Loss: 0.4609\n",
      "Epoch [11/30], Step [40/100], Loss: 0.5316\n",
      "Epoch [11/30], Step [50/100], Loss: 0.3689\n",
      "Epoch [11/30], Step [60/100], Loss: 0.2606\n",
      "Epoch [11/30], Step [70/100], Loss: 0.3083\n",
      "Epoch [11/30], Step [80/100], Loss: 0.3461\n",
      "Epoch [11/30], Step [90/100], Loss: 0.3606\n",
      "Epoch [11/30], Step [100/100], Loss: 0.4127\n",
      "Validation Accuracy: 70.50%\n",
      "Epoch [12/30], Step [10/100], Loss: 0.4629\n",
      "Epoch [12/30], Step [20/100], Loss: 0.4771\n",
      "Epoch [12/30], Step [30/100], Loss: 0.3524\n",
      "Epoch [12/30], Step [40/100], Loss: 0.3227\n",
      "Epoch [12/30], Step [50/100], Loss: 0.2454\n",
      "Epoch [12/30], Step [60/100], Loss: 0.3394\n",
      "Epoch [12/30], Step [70/100], Loss: 0.2776\n",
      "Epoch [12/30], Step [80/100], Loss: 0.3642\n",
      "Epoch [12/30], Step [90/100], Loss: 0.2868\n",
      "Epoch [12/30], Step [100/100], Loss: 0.2734\n",
      "Validation Accuracy: 74.38%\n",
      "Epoch [13/30], Step [10/100], Loss: 0.4034\n",
      "Epoch [13/30], Step [20/100], Loss: 0.3651\n",
      "Epoch [13/30], Step [30/100], Loss: 0.3884\n",
      "Epoch [13/30], Step [40/100], Loss: 0.3377\n",
      "Epoch [13/30], Step [50/100], Loss: 0.2928\n",
      "Epoch [13/30], Step [60/100], Loss: 0.3792\n",
      "Epoch [13/30], Step [70/100], Loss: 0.5169\n",
      "Epoch [13/30], Step [80/100], Loss: 0.3616\n",
      "Epoch [13/30], Step [90/100], Loss: 0.2459\n",
      "Epoch [13/30], Step [100/100], Loss: 0.2908\n",
      "Validation Accuracy: 75.12%\n",
      "Epoch [14/30], Step [10/100], Loss: 0.5071\n",
      "Epoch [14/30], Step [20/100], Loss: 0.3463\n",
      "Epoch [14/30], Step [30/100], Loss: 0.3728\n",
      "Epoch [14/30], Step [40/100], Loss: 0.4462\n",
      "Epoch [14/30], Step [50/100], Loss: 0.3443\n",
      "Epoch [14/30], Step [60/100], Loss: 0.3387\n",
      "Epoch [14/30], Step [70/100], Loss: 0.5490\n",
      "Epoch [14/30], Step [80/100], Loss: 0.4337\n",
      "Epoch [14/30], Step [90/100], Loss: 0.3352\n",
      "Epoch [14/30], Step [100/100], Loss: 0.3821\n",
      "Validation Accuracy: 76.25%\n",
      "Epoch [15/30], Step [10/100], Loss: 0.5055\n",
      "Epoch [15/30], Step [20/100], Loss: 0.3632\n",
      "Epoch [15/30], Step [30/100], Loss: 0.3141\n",
      "Epoch [15/30], Step [40/100], Loss: 0.3458\n",
      "Epoch [15/30], Step [50/100], Loss: 0.3337\n",
      "Epoch [15/30], Step [60/100], Loss: 0.3620\n",
      "Epoch [15/30], Step [70/100], Loss: 0.2418\n",
      "Epoch [15/30], Step [80/100], Loss: 0.3940\n",
      "Epoch [15/30], Step [90/100], Loss: 0.4287\n",
      "Epoch [15/30], Step [100/100], Loss: 0.3267\n",
      "Validation Accuracy: 75.38%\n",
      "Epoch [16/30], Step [10/100], Loss: 0.3523\n",
      "Epoch [16/30], Step [20/100], Loss: 0.3423\n",
      "Epoch [16/30], Step [30/100], Loss: 0.4865\n",
      "Epoch [16/30], Step [40/100], Loss: 0.2961\n",
      "Epoch [16/30], Step [50/100], Loss: 0.2497\n",
      "Epoch [16/30], Step [60/100], Loss: 0.4632\n",
      "Epoch [16/30], Step [70/100], Loss: 0.2837\n",
      "Epoch [16/30], Step [80/100], Loss: 0.3631\n",
      "Epoch [16/30], Step [90/100], Loss: 0.2543\n",
      "Epoch [16/30], Step [100/100], Loss: 0.3847\n",
      "Validation Accuracy: 73.62%\n",
      "Epoch [17/30], Step [10/100], Loss: 0.3790\n",
      "Epoch [17/30], Step [20/100], Loss: 0.3628\n",
      "Epoch [17/30], Step [30/100], Loss: 0.4332\n",
      "Epoch [17/30], Step [40/100], Loss: 0.3645\n",
      "Epoch [17/30], Step [50/100], Loss: 0.3429\n",
      "Epoch [17/30], Step [60/100], Loss: 0.2003\n",
      "Epoch [17/30], Step [70/100], Loss: 0.3618\n",
      "Epoch [17/30], Step [80/100], Loss: 0.3597\n",
      "Epoch [17/30], Step [90/100], Loss: 0.4136\n",
      "Epoch [17/30], Step [100/100], Loss: 0.3100\n",
      "Validation Accuracy: 77.38%\n",
      "Epoch [18/30], Step [10/100], Loss: 0.3664\n",
      "Epoch [18/30], Step [20/100], Loss: 0.3063\n",
      "Epoch [18/30], Step [30/100], Loss: 0.3788\n",
      "Epoch [18/30], Step [40/100], Loss: 0.4615\n",
      "Epoch [18/30], Step [50/100], Loss: 0.3278\n",
      "Epoch [18/30], Step [60/100], Loss: 0.2908\n",
      "Epoch [18/30], Step [70/100], Loss: 0.3693\n",
      "Epoch [18/30], Step [80/100], Loss: 0.4206\n",
      "Epoch [18/30], Step [90/100], Loss: 0.3906\n",
      "Epoch [18/30], Step [100/100], Loss: 0.3556\n",
      "Validation Accuracy: 76.12%\n",
      "Epoch [19/30], Step [10/100], Loss: 0.2430\n",
      "Epoch [19/30], Step [20/100], Loss: 0.3103\n",
      "Epoch [19/30], Step [30/100], Loss: 0.2667\n",
      "Epoch [19/30], Step [40/100], Loss: 0.4103\n",
      "Epoch [19/30], Step [50/100], Loss: 0.3812\n",
      "Epoch [19/30], Step [60/100], Loss: 0.3045\n",
      "Epoch [19/30], Step [70/100], Loss: 0.3161\n",
      "Epoch [19/30], Step [80/100], Loss: 0.3823\n",
      "Epoch [19/30], Step [90/100], Loss: 0.3198\n",
      "Epoch [19/30], Step [100/100], Loss: 0.3866\n",
      "Validation Accuracy: 75.75%\n",
      "Epoch [20/30], Step [10/100], Loss: 0.2987\n",
      "Epoch [20/30], Step [20/100], Loss: 0.5158\n",
      "Epoch [20/30], Step [30/100], Loss: 0.3875\n",
      "Epoch [20/30], Step [40/100], Loss: 0.2338\n",
      "Epoch [20/30], Step [50/100], Loss: 0.3544\n",
      "Epoch [20/30], Step [60/100], Loss: 0.3185\n",
      "Epoch [20/30], Step [70/100], Loss: 0.4130\n",
      "Epoch [20/30], Step [80/100], Loss: 0.2939\n",
      "Epoch [20/30], Step [90/100], Loss: 0.3948\n",
      "Epoch [20/30], Step [100/100], Loss: 0.3211\n",
      "Validation Accuracy: 75.25%\n",
      "Epoch [21/30], Step [10/100], Loss: 0.3639\n",
      "Epoch [21/30], Step [20/100], Loss: 0.4177\n",
      "Epoch [21/30], Step [30/100], Loss: 0.3064\n",
      "Epoch [21/30], Step [40/100], Loss: 0.3940\n",
      "Epoch [21/30], Step [50/100], Loss: 0.4981\n",
      "Epoch [21/30], Step [60/100], Loss: 0.3622\n",
      "Epoch [21/30], Step [70/100], Loss: 0.3851\n",
      "Epoch [21/30], Step [80/100], Loss: 0.2344\n",
      "Epoch [21/30], Step [90/100], Loss: 0.2704\n",
      "Epoch [21/30], Step [100/100], Loss: 0.3461\n",
      "Validation Accuracy: 76.00%\n",
      "Epoch [22/30], Step [10/100], Loss: 0.4197\n",
      "Epoch [22/30], Step [20/100], Loss: 0.3351\n",
      "Epoch [22/30], Step [30/100], Loss: 0.3140\n",
      "Epoch [22/30], Step [40/100], Loss: 0.3369\n",
      "Epoch [22/30], Step [50/100], Loss: 0.3025\n",
      "Epoch [22/30], Step [60/100], Loss: 0.2849\n",
      "Epoch [22/30], Step [70/100], Loss: 0.3935\n",
      "Epoch [22/30], Step [80/100], Loss: 0.1947\n",
      "Epoch [22/30], Step [90/100], Loss: 0.3376\n",
      "Epoch [22/30], Step [100/100], Loss: 0.3581\n",
      "Validation Accuracy: 74.62%\n",
      "Epoch [23/30], Step [10/100], Loss: 0.3301\n",
      "Epoch [23/30], Step [20/100], Loss: 0.3761\n",
      "Epoch [23/30], Step [30/100], Loss: 0.2858\n",
      "Epoch [23/30], Step [40/100], Loss: 0.2039\n",
      "Epoch [23/30], Step [50/100], Loss: 0.4423\n",
      "Epoch [23/30], Step [60/100], Loss: 0.3486\n",
      "Epoch [23/30], Step [70/100], Loss: 0.3031\n",
      "Epoch [23/30], Step [80/100], Loss: 0.3861\n",
      "Epoch [23/30], Step [90/100], Loss: 0.4339\n",
      "Epoch [23/30], Step [100/100], Loss: 0.3105\n",
      "Validation Accuracy: 61.25%\n",
      "Epoch [24/30], Step [10/100], Loss: 0.2669\n",
      "Epoch [24/30], Step [20/100], Loss: 0.2759\n",
      "Epoch [24/30], Step [30/100], Loss: 0.3015\n",
      "Epoch [24/30], Step [40/100], Loss: 0.2977\n",
      "Epoch [24/30], Step [50/100], Loss: 0.3459\n",
      "Epoch [24/30], Step [60/100], Loss: 0.2337\n",
      "Epoch [24/30], Step [70/100], Loss: 0.4047\n",
      "Epoch [24/30], Step [80/100], Loss: 0.3708\n",
      "Epoch [24/30], Step [90/100], Loss: 0.3698\n",
      "Epoch [24/30], Step [100/100], Loss: 0.4780\n",
      "Validation Accuracy: 64.88%\n",
      "Epoch [25/30], Step [10/100], Loss: 0.3400\n",
      "Epoch [25/30], Step [20/100], Loss: 0.3942\n",
      "Epoch [25/30], Step [30/100], Loss: 0.3774\n",
      "Epoch [25/30], Step [40/100], Loss: 0.2972\n",
      "Epoch [25/30], Step [50/100], Loss: 0.2930\n",
      "Epoch [25/30], Step [60/100], Loss: 0.4199\n",
      "Epoch [25/30], Step [70/100], Loss: 0.3125\n",
      "Epoch [25/30], Step [80/100], Loss: 0.5199\n",
      "Epoch [25/30], Step [90/100], Loss: 0.3662\n",
      "Epoch [25/30], Step [100/100], Loss: 0.4004\n",
      "Validation Accuracy: 73.12%\n",
      "Epoch [26/30], Step [10/100], Loss: 0.3553\n",
      "Epoch [26/30], Step [20/100], Loss: 0.3111\n",
      "Epoch [26/30], Step [30/100], Loss: 0.4550\n",
      "Epoch [26/30], Step [40/100], Loss: 0.2626\n",
      "Epoch [26/30], Step [50/100], Loss: 0.4261\n",
      "Epoch [26/30], Step [60/100], Loss: 0.3644\n",
      "Epoch [26/30], Step [70/100], Loss: 0.4053\n",
      "Epoch [26/30], Step [80/100], Loss: 0.3375\n",
      "Epoch [26/30], Step [90/100], Loss: 0.1430\n",
      "Epoch [26/30], Step [100/100], Loss: 0.3812\n",
      "Validation Accuracy: 75.88%\n",
      "Epoch [27/30], Step [10/100], Loss: 0.3383\n",
      "Epoch [27/30], Step [20/100], Loss: 0.2824\n",
      "Epoch [27/30], Step [30/100], Loss: 0.3362\n",
      "Epoch [27/30], Step [40/100], Loss: 0.2564\n",
      "Epoch [27/30], Step [50/100], Loss: 0.4350\n",
      "Epoch [27/30], Step [60/100], Loss: 0.3839\n",
      "Epoch [27/30], Step [70/100], Loss: 0.3165\n",
      "Epoch [27/30], Step [80/100], Loss: 0.3018\n",
      "Epoch [27/30], Step [90/100], Loss: 0.5011\n",
      "Epoch [27/30], Step [100/100], Loss: 0.2668\n",
      "Validation Accuracy: 74.75%\n",
      "Epoch [28/30], Step [10/100], Loss: 0.3553\n",
      "Epoch [28/30], Step [20/100], Loss: 0.2827\n",
      "Epoch [28/30], Step [30/100], Loss: 0.4390\n",
      "Epoch [28/30], Step [40/100], Loss: 0.3785\n",
      "Epoch [28/30], Step [50/100], Loss: 0.6018\n",
      "Epoch [28/30], Step [60/100], Loss: 0.3816\n",
      "Epoch [28/30], Step [70/100], Loss: 0.3422\n",
      "Epoch [28/30], Step [80/100], Loss: 0.4298\n",
      "Epoch [28/30], Step [90/100], Loss: 0.4203\n",
      "Epoch [28/30], Step [100/100], Loss: 0.3967\n",
      "Validation Accuracy: 75.88%\n",
      "Epoch [29/30], Step [10/100], Loss: 0.2830\n",
      "Epoch [29/30], Step [20/100], Loss: 0.2576\n",
      "Epoch [29/30], Step [30/100], Loss: 0.4175\n",
      "Epoch [29/30], Step [40/100], Loss: 0.3531\n",
      "Epoch [29/30], Step [50/100], Loss: 0.4251\n",
      "Epoch [29/30], Step [60/100], Loss: 0.3723\n",
      "Epoch [29/30], Step [70/100], Loss: 0.2324\n",
      "Epoch [29/30], Step [80/100], Loss: 0.3585\n",
      "Epoch [29/30], Step [90/100], Loss: 0.2739\n",
      "Epoch [29/30], Step [100/100], Loss: 0.2940\n",
      "Validation Accuracy: 76.00%\n",
      "Epoch [30/30], Step [10/100], Loss: 0.2558\n",
      "Epoch [30/30], Step [20/100], Loss: 0.3394\n",
      "Epoch [30/30], Step [30/100], Loss: 0.5281\n",
      "Epoch [30/30], Step [40/100], Loss: 0.3146\n",
      "Epoch [30/30], Step [50/100], Loss: 0.3110\n",
      "Epoch [30/30], Step [60/100], Loss: 0.4492\n",
      "Epoch [30/30], Step [70/100], Loss: 0.2120\n",
      "Epoch [30/30], Step [80/100], Loss: 0.2914\n",
      "Epoch [30/30], Step [90/100], Loss: 0.3096\n",
      "Epoch [30/30], Step [100/100], Loss: 0.3564\n",
      "Validation Accuracy: 75.88%\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "num_epochs = 30\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Prepare Dataset\n",
    "dataset = PointCloudDataset(root_dir=r\"C:\\Users\\Muhammad Hassan\\Desktop\\fraunhofer\\Training Datasets\\Simple Shapes Dataset\")\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Data Loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Model, Loss, Optimizer\n",
    "model = PointNet(num_classes=4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, (points, labels) in enumerate(train_loader):\n",
    "        points = points.transpose(1, 2).float()  # Reshape to (batch_size, 3, num_points)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(points)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for points, labels in val_loader:\n",
    "            points = points.transpose(1, 2).float()\n",
    "            outputs = model(points)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Validation Accuracy: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:/Users/Muhammad Hassan/Desktop/fraunhofer/CAD Dataset Maker algoritham/Trained 3.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "\n",
    "# Saving the trained model\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # Hide the main window\n",
    "save_path = filedialog.asksaveasfilename(\n",
    "    title='Save Trained Model',\n",
    "    filetypes=[('PyTorch Model', '*.pth')],\n",
    "    defaultextension=[('PyTorch Model', '*.pth')]\n",
    ")\n",
    "\n",
    "if save_path:\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "else:\n",
    "    print(\"Model save operation cancelled.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tkinter import filedialog\n",
    "import tkinter as tk\n",
    "\n",
    "def load_model(model_class, num_classes=4, model_path=None):\n",
    "    if model_path is None:\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()\n",
    "        model_path = filedialog.askopenfilename(title='Select Trained Model', filetypes=[('PyTorch Model', '*.pth')])\n",
    "    \n",
    "    if model_path:\n",
    "        model = model_class(num_classes=num_classes)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "        model.eval()\n",
    "        return model\n",
    "    else:\n",
    "        print(\"No model selected\")\n",
    "        return None\n",
    "\n",
    "# Usage\n",
    "model = load_model(PointNet, num_classes=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 2\n",
      "Recommended manufacturing processes: Chamfer or Fillets are detected. We need Milling and Turning\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(PointNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.fc1 = nn.Linear(128, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, num_classes)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        \n",
    "        x = F.adaptive_max_pool1d(x, 1).squeeze(-1)\n",
    "        \n",
    "        x = F.relu(self.bn3(self.fc1(x)))\n",
    "        \n",
    "        x = F.relu(self.bn4(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1) \n",
    "\n",
    "\n",
    "def stl_to_point_cloud(stl_file_path, number_of_points=2048):\n",
    "    mesh = o3d.io.read_triangle_mesh(stl_file_path)\n",
    "    if not mesh.is_watertight():\n",
    "        mesh = mesh.remove_duplicated_triangles()\n",
    "        mesh = mesh.remove_duplicated_vertices()\n",
    "        mesh = mesh.remove_degenerate_triangles()\n",
    "    point_cloud = mesh.sample_points_poisson_disk(number_of_points)\n",
    "    return np.asarray(point_cloud.points)\n",
    "\n",
    "# Prediction function\n",
    "def predict(model, point_cloud):\n",
    "    point_cloud = np.asarray(point_cloud)\n",
    "    point_cloud = torch.from_numpy(point_cloud).float()\n",
    "    point_cloud = point_cloud.transpose(0, 1).unsqueeze(0)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(point_cloud)\n",
    "        _, predicted = torch.max(outputs, dim=1)  # Ensure this is the right dimension\n",
    "        return predicted.item()  # This should return a scalar value\n",
    "\n",
    "\n",
    "def select_stl_and_predict(model):\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    stl_file_path = filedialog.askopenfilename(title='Select STL File', filetypes=[('STL Files', '*.stl')])\n",
    "\n",
    "    if stl_file_path:\n",
    "        point_cloud = stl_to_point_cloud(stl_file_path)\n",
    "        prediction = predict(model, point_cloud)\n",
    "        print(\"Predicted class:\", prediction)\n",
    "\n",
    "        # Define a mapping from class index to manufacturing processes\n",
    "        manufacturing_processes = {\n",
    "            0: \"Holes are Detected. We need Drilling and Boring\",\n",
    "            1: \"Chamfer or Fillets are detected. We need Milling and Turning\",\n",
    "            2: \"Chamfer or Fillets are detected. We need Milling and Turning\",\n",
    "            3: \"Pockets are detected.We need Milling and Boring\"\n",
    "        }\n",
    "\n",
    "        # Use the prediction to get the respective manufacturing process\n",
    "        process = manufacturing_processes.get(prediction, \"Unknown class\")\n",
    "        print(\"Recommended manufacturing processes:\", process)\n",
    "    else:\n",
    "        print(\"No STL file selected\")\n",
    "\n",
    "# Execute the prediction using the pre-trained model\n",
    "if model:\n",
    "    select_stl_and_predict(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
